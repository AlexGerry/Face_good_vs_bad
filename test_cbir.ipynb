{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.BOVW import BOVW\n",
    "from src.ColorHistogram import ColorHistogram\n",
    "from src.DeepModel import DeepModel\n",
    "from src.CombinedModel import CombinedModel\n",
    "from src.CNN import CNN\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "import dill\n",
    "from tqdm import tqdm\n",
    "from time import perf_counter\n",
    "import os\n",
    "from src.Preprocess import find_face_and_preprocess\n",
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split new features (only if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_path = \"./src/CNN_transfer/cnn_withus_maxpool/cnn_train_features.pkl\"\n",
    "#labels_path = \"./src/CNN_transfer/cnn_withus_maxpool/cnn_train_labels.pkl\"\n",
    "#\n",
    "#with open(feature_path, 'rb') as f: feature = dill.load(f)\n",
    "#with open(labels_path, 'rb') as f: labels = dill.load(f)\n",
    "#\n",
    "#feature_savory = [feature[i] for i in np.where(np.asarray(labels)=='savory')[0]]\n",
    "#feature_unsavory = [feature[i] for i in np.where(np.asarray(labels)=='unsavory')[0]]\n",
    "#\n",
    "#with open(\"./src/CNN_transfer/cnn_withus_maxpool/feature_savory.pkl\", 'wb') as f: feature = dill.dump(feature_savory, f)\n",
    "#with open(\"./src/CNN_transfer/cnn_withus_maxpool/feature_unsavory.pkl\", 'wb') as f: feature = dill.dump(feature_unsavory, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOVW paths\n",
    "new_bovw_path = './src/BOVW/bovw_withus/bovw.pkl'\n",
    "new_bovw_features = \"./src/BOVW/bovw_withus/train_bovw.pkl\"\n",
    "new_bovw_savory = './src/BOVW/bovw_withus/feature_savory.pkl'\n",
    "new_bovw_unsavory = './src/BOVW/bovw_withus/feature_unsavory.pkl'\n",
    "new_train_image_path_bovw = './src/BOVW/bovw_withus/train_paths.pkl'\n",
    "# Color paths\n",
    "new_color_path = \"./src/Color/color_withus/histogram_model.pkl\"\n",
    "new_color_features = \"./src/Color/color_withus/train_color_histogram.pkl\"\n",
    "new_color_savory = \"./src/Color/color_withus/feature_savory.pkl\"\n",
    "new_color_unsavory = \"./src/Color/color_withus/feature_unsavory.pkl\"\n",
    "new_train_image_path_color = './src/Color/color_withus/train_paths.pkl'\n",
    "# Combined paths\n",
    "new_combined_path = \"./src/Combined_descriptors/combined_withus/combined_model.pkl\"\n",
    "# Siamese model paths\n",
    "classifier_path = \"./src/CNN_training/Classifier_withus/svm_final_nu03.sav\"\n",
    "siamese_embeddings = \"./src/CNN_training/final_siamese_embedding_model_withus\"\n",
    "siamese_features = \"./src/CNN_training/Features_withus/feature_final.pkl\"\n",
    "siamese_savory = \"./src/CNN_training/Features_withus/feature_savory.pkl\"\n",
    "siamese_unsavory = \"./src/CNN_training/Features_withus/feature_unsavory.pkl\"\n",
    "image_train_paths = \"./src/CNN_training/Features_withus/path_final.pkl\"\n",
    "# CNN\n",
    "cnn_path = './src/CNN/trained_cnn/'\n",
    "cnn_features = \"./src/CNN/cnn_withus_maxpool/cnn_train_features.pkl\"\n",
    "cnn_savory = './src/CNN/cnn_withus/feature_savory.pkl'\n",
    "cnn_unsavory = './src/CNN/cnn_withus/feature_unsavory.pkl'\n",
    "cnn_image_train_paths = \"./src/CNN/cnn_withus/cnn_train_paths.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Model loaded from src\\CNN_training\\final_siamese_embedding_model_withus\n",
      "KDTree computed in: 0.699861300000002\n"
     ]
    }
   ],
   "source": [
    "model = DeepModel(\n",
    "        classifier_path, \n",
    "        siamese_embeddings, \n",
    "        siamese_features,\n",
    "        image_train_paths, \n",
    "        siamese_savory,\n",
    "        siamese_unsavory, \n",
    "        (200, 200)\n",
    "        )\n",
    "color_model = ColorHistogram.load_model(new_color_path)\n",
    "bovw_model = BOVW.load_model(new_bovw_path)\n",
    "combined_model = CombinedModel.load_model(new_combined_path)\n",
    "cnn_model = CNN(cnn_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate CBIR performances on new image of ourselves (live version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import VideoCapture\n",
    "from PIL import Image\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageSubplot(similar_s, similar_u, dist_s, dist_u):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(20, 10))\n",
    "    fig.suptitle('** I row: Savory - II row Unsavory **', fontsize=15)\n",
    "    idx = np.argsort(np.argsort(np.concatenate((dist_s[0], dist_u[0]))))\n",
    "    for i, path in enumerate(similar_s):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.title(f\"/{i+1} - Rank: {idx[i]+1} - dist: {np.round(dist_s[0][i], decimals=3)}\")\n",
    "        plt.axis('off')\n",
    "        plt.imshow(plt.imread(path))\n",
    "    for i, path in enumerate(similar_u):\n",
    "        plt.subplot(2, 5, i+6)\n",
    "        plt.title(f\"/{i+6} - Rank: {idx[i+5]+1}- dist: {np.round(dist_u[0][i], decimals=3)}\")\n",
    "        plt.axis('off')\n",
    "        plt.imshow(plt.imread(path))\n",
    "    #plt.savefig(\"./cbir.jpg\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def imageSubplot_perfo(preds, preds_score, similar_s, similar_u, dist_s, dist_u):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(20, 10))\n",
    "    if preds =='0':\n",
    "        preds = \"savory\"\n",
    "    elif preds =='1':\n",
    "        preds = \"unsavory\"\n",
    "    confidence = np.round(np.max(preds_score), decimals=2)*100 if preds_score is not None else \"...\"\n",
    "    fig.suptitle(f'* You are: {preds}, with {confidence} confidence! *', fontsize=15)\n",
    "    idx = np.argsort(np.argsort(np.concatenate((dist_s, dist_u))))\n",
    "    for i, path in enumerate(similar_s):\n",
    "        label = similar_s[i].split(\"\\\\\")[-2]\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.title(f\"/{i+1} - {label} - Rank: {idx[i]+1} - dist: {np.round(dist_s[i], decimals=3)}\")\n",
    "        plt.axis('off')\n",
    "        plt.imshow(plt.imread(path))\n",
    "    for i, path in enumerate(similar_u):\n",
    "        label = similar_u[i].split(\"\\\\\")[-2]\n",
    "        plt.subplot(2, 5, i+6)\n",
    "        plt.title(f\"/{i+6} - {label} - Rank: {idx[i+5]+1} - dist: {np.round(dist_u[i], decimals=3)}\")\n",
    "        plt.axis('off')\n",
    "        plt.imshow(plt.imread(path))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_demo():  \n",
    "    try:\n",
    "        cam = VideoCapture(0)\n",
    "        print(\"recording...\")\n",
    "        while True and cam.isOpened():\n",
    "            s, frame = cam.read()   # frame is a numpy.ndarray\n",
    "            cv2.imshow('frame', frame)\n",
    "            if not s:\n",
    "                break\n",
    "            if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "                img = Image.fromarray(frame).convert('RGB')\n",
    "                r, g, b = img.split()\n",
    "                result = Image.merge('RGB', (b, g, r))  # To resolve blueish image\n",
    "                result.save(\"./temp.jpg\")\n",
    "                faces = find_face_and_preprocess(\"./temp.jpg\", detector)\n",
    "                if len(faces) >= 1:\n",
    "                    for i, f in enumerate(faces):\n",
    "                        f = (f*255).astype('uint8')\n",
    "                        image = Image.fromarray(f)\n",
    "                        image.save(\"./temp_crop.jpg\")\n",
    "                        result, most_similar_s, most_similar_u, feature, dist_s, dist_u = BOVW.cbir(new_bovw_path, \"./temp_crop.jpg\", new_bovw_savory, new_bovw_unsavory, new_train_image_path_bovw)\n",
    "                        print(result[0])\n",
    "                        # CBIR\n",
    "                        imageSubplot(most_similar_s, most_similar_u, dist_s, dist_u)\n",
    "                else: print(\"faccia non trovata...\")\n",
    "                break\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    except Exception as e:\n",
    "        print(\"error...\", e)\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press q to get image from recorder\n",
    "start_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"C:/Users/Jarvis/Desktop/io.jpg\"\n",
    "\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "faces = find_face_and_preprocess(img_path, detector)\n",
    "if len(faces) >= 1:\n",
    "    for i, f in enumerate(faces):\n",
    "        f = (f*255).astype('uint8')\n",
    "        image = Image.fromarray(f)\n",
    "        image.save(temp_dir.name+\"./temp_crop.jpg\")\n",
    "        #pred_score, result, most_similar, feature, dist = ColorHistogram.cbir_performance(new_color_path, temp_dir.name+\"./temp_crop.jpg\", new_color_features, new_train_image_path_color, k=10)                        \n",
    "        #pred_score, result, most_similar, feature, dist = BOVW.cbir_performance(new_bovw_path, temp_dir.name+\"./temp_crop.jpg\", new_bovw_features, new_train_image_path_color, k=10)                        \n",
    "        #pred_score, result, most_similar, feature, dist = CombinedModel.cbir_performance(new_combined_path, temp_dir.name+\"./temp_crop.jpg\", None, new_train_image_path_color, k=10)                        \n",
    "        #pred_score, result, most_similar, feature, dist = cnn_model.cbir_performance(temp_dir.name+\"./temp_crop.jpg\", cnn_features, cnn_image_train_paths, k=10)                        \n",
    "        pred_score, result, most_similar, feature, dist = model.cbir_performance(image, k=10)                        \n",
    "        # CBIR\n",
    "        len_similar = len(most_similar)\n",
    "        len_dists = len(dist[0])\n",
    "        most_similar_s = most_similar[:len_similar//2]\n",
    "        most_similar_u = most_similar[len_similar//2:]\n",
    "        dist_s = dist[0][:len_dists//2]\n",
    "        dist_u = dist[0][len_dists//2:]\n",
    "        imageSubplot_perfo(result[0], pred_score, most_similar_s, most_similar_u, dist_s, dist_u)\n",
    "else: print(\"faccia non trovata...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate CBIR performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "query_dataset = \"../dataset/query_cbir/\"\n",
    "paths = list(Path(query_dataset).rglob(\"*.jpg\"))\n",
    "\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "most_similar_color, most_similar_bovw, most_similar_comb, most_similar_cnn, most_similar_siamese = [], [], [], [], []\n",
    "gt = []\n",
    "\n",
    "for image_path in paths:\n",
    "    gt.append(image_path.parts[-2])\n",
    "    print(image_path)\n",
    "    faces = find_face_and_preprocess(image_path, detector)\n",
    "    if faces is not None and len(faces) >= 1:\n",
    "        for i, f in enumerate(faces):\n",
    "            f = (f*255).astype('uint8')\n",
    "            image = Image.fromarray(f)\n",
    "            image.save(temp_dir.name+\"./temp_crop.jpg\")\n",
    "            _, _, similar_color, _, _ = ColorHistogram.cbir_performance(new_color_path, temp_dir.name+\"./temp_crop.jpg\", new_color_features, new_train_image_path_color, k=10)                        \n",
    "            _, _, similar_bovw, _, _ = BOVW.cbir_performance(new_bovw_path, temp_dir.name+\"./temp_crop.jpg\", new_bovw_features, new_train_image_path_color, k=10)                        \n",
    "            _, _, similar_comb, _, _ = CombinedModel.cbir_performance(new_combined_path, temp_dir.name+\"./temp_crop.jpg\", None, new_train_image_path_color, k=10)                        \n",
    "            _, _, similar_cnn, _, _ = cnn_model.cbir_performance(temp_dir.name+\"./temp_crop.jpg\", cnn_features, cnn_image_train_paths, k=10)                        \n",
    "            _, _, similar_siamese, _, _ = model.cbir_performance(image, k=10)                        \n",
    "            most_similar_color.append(similar_color)\n",
    "            most_similar_bovw.append(similar_bovw)\n",
    "            most_similar_comb.append(similar_comb)\n",
    "            most_similar_cnn.append(similar_cnn)\n",
    "            most_similar_siamese.append(similar_siamese)            \n",
    "    else: print(\"faccia non trovata...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_color = [[i.split(\"\\\\\")[-2] for i in x] for x in most_similar_color]\n",
    "most_similar_bovw = [[i.split(\"\\\\\")[-2] for i in x] for x in most_similar_bovw]\n",
    "most_similar_comb = [[i.split(\"\\\\\")[-2] for i in x] for x in most_similar_comb]\n",
    "most_similar_cnn = [[i.split(\"\\\\\")[-2] for i in x] for x in most_similar_cnn]\n",
    "most_similar_siamese = [[i.split(\"\\\\\")[-2] for i in x] for x in most_similar_siamese]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(actual, predicted, k=10):\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    if not actual: return 0.0\n",
    "    if k > len(predicted): return None\n",
    "    for i,p in enumerate(predicted[:k]):\n",
    "        if p == actual:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "    return score / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [most_similar_color, most_similar_bovw, most_similar_comb, most_similar_cnn, most_similar_siamese]\n",
    "models_name = [\"Color Histogram\", \"BOVW\", \"BOVW+Color\", \"CNN\", \"Siamese\"]\n",
    "\n",
    "def get_mapk(models, models_name, K):\n",
    "    aps = {}\n",
    "    for y, m in enumerate(models):\n",
    "        aps[models_name[y]] = []\n",
    "        for i in range(len(gt)):\n",
    "            for K in [K]:\n",
    "                aps[models_name[y]].append(average_precision(gt[i], m[i], k=K))\n",
    "        aps[models_name[y]] = np.mean(aps[models_name[y]])\n",
    "    return aps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Color Histogram': 0.5,\n",
       " 'BOVW': 0.6,\n",
       " 'BOVW+Color': 0.55,\n",
       " 'CNN': 0.75,\n",
       " 'Siamese': 0.65}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mapk(models, models_name, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Color Histogram': 0.45133333333333325,\n",
       " 'BOVW': 0.4423333333333333,\n",
       " 'BOVW+Color': 0.47733333333333333,\n",
       " 'CNN': 0.6875,\n",
       " 'Siamese': 0.46533333333333327}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mapk(models, models_name, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Color Histogram': 0.44391865079365084,\n",
       " 'BOVW': 0.436827380952381,\n",
       " 'BOVW+Color': 0.43923015873015875,\n",
       " 'CNN': 0.6559781746031745,\n",
       " 'Siamese': 0.4347996031746031}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mapk(models, models_name, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb528fd416c0ff975b48fb7dd275c91a0873308d73117ccfdcc096d65948d1b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
