{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from keras import layers, regularizers, optimizers, losses\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocessing\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.utils import set_random_seed, image_dataset_from_directory\n",
    "from training import prepare_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "DATASET_PATH = \"../../../dataset/\"\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = (224, 224, 3, )\n",
    "\n",
    "# `PYTHONHASHSEED` environment variable\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "# Python built-in random, numpy(+ scikit) and tensorflow seed\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset...\n",
      "Found 11220 files belonging to 2 classes.\n",
      "Train dataset loaded!\n",
      "Labels in the dataset:  ['savory', 'unsavory']\n",
      "Loading validation dataset...\n",
      "Found 600 files belonging to 2 classes.\n",
      "Validation dataset loaded!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "print(\"Loading train dataset...\")\n",
    "train_ds = image_dataset_from_directory(\n",
    "    directory=os.path.join(DATASET_PATH, \"train\"),\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=None,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=None,\n",
    "    seed=SEED\n",
    "    )\n",
    "print(\"Train dataset loaded!\")\n",
    "print(\"Labels in the dataset: \", train_ds.class_names)\n",
    "\n",
    "# Load the validation dataset\n",
    "print(\"Loading validation dataset...\")\n",
    "val_ds = image_dataset_from_directory(\n",
    "    directory=os.path.join(DATASET_PATH, \"valid\"),\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=None,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=None,\n",
    "    seed=SEED\n",
    "    )\n",
    "print(\"Validation dataset loaded!\")\n",
    "\n",
    "train_ds = train_ds.shuffle(256, seed=SEED, reshuffle_each_iteration=False).take(int(len(train_ds)*0.25))\n",
    "val_ds = val_ds.shuffle(128, seed=SEED, reshuffle_each_iteration=False).take(int(len(val_ds)*0.25))\n",
    "\n",
    "train_ds = prepare_dataset(train_ds, augment=True)\n",
    "val_ds = prepare_dataset(val_ds)\n",
    "\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.Input(shape=(INPUT_SHAPE)))\n",
    "    \n",
    "    # Search first conv\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Choice('conv_1_filter', values=[32, 64]),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(1e-2),\n",
    "        strides=(1, 1)\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D(pool_size=hp.Choice('pool_1_size', values = [3,5])))\n",
    "    \n",
    "    # Choose how many conv layers\n",
    "    for i in range(hp.Int(\"num_Convolutional_layers\", 1, 2)):\n",
    "        model.add(\n",
    "            layers.Conv2D(\n",
    "                filters=hp.Choice(f\"conv_{i}_filters\", values=[64, 128, 256]),\n",
    "                kernel_size=(3, 3),\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=regularizers.l2(1e-2),\n",
    "                strides=(1, 1)\n",
    "            )\n",
    "        )\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Choose how many classifier\n",
    "    for i in range(hp.Int(\"num_FullyConnected_layers\", 1, 2)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Choice(f\"units_{i}\", values=[64, 128, 256]),\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=regularizers.l2(1e-2)\n",
    "            )\n",
    "        )\n",
    "        if hp.Boolean(\"dropout\"): model.add(layers.Dropout(rate=0.25))\n",
    "    \n",
    "    model.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    # Choose the optimizer\n",
    "    hp_optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'adamax'], default = 'adamax')\n",
    "    optimizer = tf.keras.optimizers.get(hp_optimizer)\n",
    "    # Choose the learning rate\n",
    "    optimizer.learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-2], default = 1e-3)\n",
    "                                        \n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss=\"categorical_crossentropy\", \n",
    "                    metrics = [\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./keras_tuner/\", exist_ok=True)\n",
    "tuner = kt.BayesianOptimization(build_model,\n",
    "                                objective=kt.Objective('val_loss', direction=\"min\"),\n",
    "                                directory='./keras_tuner',\n",
    "                                max_trials = 20, overwrite=False,\n",
    "                                project_name='tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 10\n",
      "conv_1_filter (Choice)\n",
      "{'default': 32, 'conditions': [], 'values': [32, 64], 'ordered': True}\n",
      "conv_1_kernel (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [3, 5], 'ordered': True}\n",
      "pool_1_size (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [3, 5], 'ordered': True}\n",
      "num_Convolutional_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 2, 'step': 1, 'sampling': None}\n",
      "conv_0_filters (Choice)\n",
      "{'default': 64, 'conditions': [], 'values': [64, 128, 256], 'ordered': True}\n",
      "num_FullyConnected_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 2, 'step': 1, 'sampling': None}\n",
      "units_0 (Choice)\n",
      "{'default': 64, 'conditions': [], 'values': [64, 128, 256], 'ordered': True}\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "optimizer (Choice)\n",
      "{'default': 'adamax', 'conditions': [], 'values': ['adam', 'rmsprop', 'adamax'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.01], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "# The combination of all parameters\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 22s]\n",
      "val_loss: 0.6964443325996399\n",
      "\n",
      "Best val_loss So Far: 0.5550560355186462\n",
      "Total elapsed time: 00h 08m 41s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`x0` violates bound constraints.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alessandro\\Desktop\\universit√†\\visual image\\Face_good_vs_bad\\src\\CNN_training\\best_parameters.ipynb Cella 7\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/universit%C3%A0/visual%20image/Face_good_vs_bad/src/CNN_training/best_parameters.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m callbacks \u001b[39m=\u001b[39m [early_stopping, lr_scheduler]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/universit%C3%A0/visual%20image/Face_good_vs_bad/src/CNN_training/best_parameters.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Search best hyperparameter\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/universit%C3%A0/visual%20image/Face_good_vs_bad/src/CNN_training/best_parameters.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(train_ds, epochs\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mval_ds, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:173\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    172\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_create_trial()\n\u001b[1;32m--> 173\u001b[0m     trial \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moracle\u001b[39m.\u001b[39;49mcreate_trial(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtuner_id)\n\u001b[0;32m    174\u001b[0m     \u001b[39mif\u001b[39;00m trial\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mSTOPPED:\n\u001b[0;32m    175\u001b[0m         \u001b[39m# Oracle triggered exit.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m         tf\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mOracle triggered exit\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\engine\\oracle.py:194\u001b[0m, in \u001b[0;36mOracle.create_trial\u001b[1;34m(self, tuner_id)\u001b[0m\n\u001b[0;32m    192\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpopulate_space(trial_id)\n\u001b[0;32m    195\u001b[0m     status \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    196\u001b[0m     values \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m response \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\tuners\\bayesian.py:270\u001b[0m, in \u001b[0;36mBayesianOptimizationOracle.populate_space\u001b[1;34m(self, trial_id)\u001b[0m\n\u001b[0;32m    265\u001b[0m x_seeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_random_state\u001b[39m.\u001b[39muniform(\n\u001b[0;32m    266\u001b[0m     bounds[:, \u001b[39m0\u001b[39m], bounds[:, \u001b[39m1\u001b[39m], size\u001b[39m=\u001b[39m(num_restarts, bounds\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m    267\u001b[0m )\n\u001b[0;32m    268\u001b[0m \u001b[39mfor\u001b[39;00m x_try \u001b[39min\u001b[39;00m x_seeds:\n\u001b[0;32m    269\u001b[0m     \u001b[39m# Sign of score is flipped when maximizing.\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m     result \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49moptimize\u001b[39m.\u001b[39;49mminimize(\n\u001b[0;32m    271\u001b[0m         _upper_confidence_bound, x0\u001b[39m=\u001b[39;49mx_try, bounds\u001b[39m=\u001b[39;49mbounds, method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    272\u001b[0m     )\n\u001b[0;32m    273\u001b[0m     result_fun \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mfun \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misscalar(result\u001b[39m.\u001b[39mfun) \u001b[39melse\u001b[39;00m result\u001b[39m.\u001b[39mfun[\u001b[39m0\u001b[39m]\n\u001b[0;32m    274\u001b[0m     \u001b[39mif\u001b[39;00m result_fun \u001b[39m<\u001b[39m optimal_val:\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\_minimize.py:699\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    696\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    697\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    698\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 699\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    700\u001b[0m                            callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[0;32m    701\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    702\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[0;32m    703\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:362\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    356\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[0;32m    357\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    358\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    360\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 362\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[0;32m    363\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    364\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[0;32m    365\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:286\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m    285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun()\n\u001b[1;32m--> 286\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_grad\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated:\n\u001b[1;32m--> 256\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad_impl()\n\u001b[0;32m    257\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[1;34m()\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun()\n\u001b[0;32m    172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mngev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 173\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg \u001b[39m=\u001b[39m approx_derivative(fun_wrapped, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, f0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf,\n\u001b[0;32m    174\u001b[0m                            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfinite_diff_options)\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:470\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[1;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`f0` passed has more than 1 dimension.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many((x0 \u001b[39m<\u001b[39m lb) \u001b[39m|\u001b[39m (x0 \u001b[39m>\u001b[39m ub)):\n\u001b[1;32m--> 470\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`x0` violates bound constraints.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    472\u001b[0m \u001b[39mif\u001b[39;00m as_linear_operator:\n\u001b[0;32m    473\u001b[0m     \u001b[39mif\u001b[39;00m rel_step \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: `x0` violates bound constraints."
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=12, min_delta=0.0001, restore_best_weights=True, verbose=1)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, verbose=1)\n",
    "callbacks = [early_stopping, lr_scheduler]\n",
    "# Search best hyperparameter\n",
    "tuner.search(train_ds, epochs=150, validation_data=val_ds, shuffle=True, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 220, 220, 32)      2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 44, 44, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 42, 42, 256)       73984     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 21, 21, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,018\n",
      "Trainable params: 93,506\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the top model\n",
    "models = tuner.get_best_models(num_models=1)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# best_model.build(input_shape=INPUT_SHAPE)\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./keras_tuner\\tuned_model\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000016D206CFFD0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 32\n",
      "conv_1_kernel: 5\n",
      "pool_1_size: 5\n",
      "num_Convolutional_layers: 1\n",
      "conv_0_filters: 256\n",
      "num_FullyConnected_layers: 1\n",
      "units_0: 64\n",
      "dropout: False\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "conv_1_filters: 128\n",
      "units_1: 128\n",
      "Score: 0.5550560355186462\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 32\n",
      "conv_1_kernel: 5\n",
      "pool_1_size: 5\n",
      "num_Convolutional_layers: 1\n",
      "conv_0_filters: 256\n",
      "num_FullyConnected_layers: 1\n",
      "units_0: 64\n",
      "dropout: False\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "conv_1_filters: 64\n",
      "units_1: 64\n",
      "Score: 0.6116705536842346\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 32\n",
      "conv_1_kernel: 5\n",
      "pool_1_size: 5\n",
      "num_Convolutional_layers: 1\n",
      "conv_0_filters: 256\n",
      "num_FullyConnected_layers: 1\n",
      "units_0: 64\n",
      "dropout: True\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "conv_1_filters: 64\n",
      "units_1: 64\n",
      "Score: 0.6132145524024963\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 32\n",
      "conv_1_kernel: 5\n",
      "pool_1_size: 5\n",
      "num_Convolutional_layers: 1\n",
      "conv_0_filters: 256\n",
      "num_FullyConnected_layers: 1\n",
      "units_0: 64\n",
      "dropout: True\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "conv_1_filters: 128\n",
      "units_1: 128\n",
      "Score: 0.6301616430282593\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 32\n",
      "conv_1_kernel: 5\n",
      "pool_1_size: 5\n",
      "num_Convolutional_layers: 1\n",
      "conv_0_filters: 256\n",
      "num_FullyConnected_layers: 1\n",
      "units_0: 64\n",
      "dropout: False\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "conv_1_filters: 256\n",
      "units_1: 128\n",
      "Score: 0.6340587735176086\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 32\n",
      "conv_1_kernel: 3\n",
      "pool_1_size: 5\n",
      "num_Convolutional_layers: 2\n",
      "conv_0_filters: 128\n",
      "num_FullyConnected_layers: 2\n",
      "units_0: 128\n",
      "dropout: True\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "conv_1_filters: 64\n",
      "units_1: 64\n",
      "Score: 0.6497594118118286\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 32\n",
      "conv_1_kernel: 5\n",
      "pool_1_size: 5\n",
      "num_Convolutional_layers: 1\n",
      "conv_0_filters: 256\n",
      "num_FullyConnected_layers: 1\n",
      "units_0: 256\n",
      "dropout: False\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "conv_1_filters: 64\n",
      "units_1: 64\n",
      "Score: 0.6711521148681641\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 64\n",
      "conv_1_kernel: 5\n",
      "pool_1_size: 3\n",
      "num_Convolutional_layers: 1\n",
      "conv_0_filters: 256\n",
      "num_FullyConnected_layers: 1\n",
      "units_0: 64\n",
      "dropout: True\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.01\n",
      "conv_1_filters: 256\n",
      "units_1: 256\n",
      "Score: 0.6931664347648621\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 32\n",
      "conv_1_kernel: 5\n",
      "pool_1_size: 5\n",
      "num_Convolutional_layers: 1\n",
      "conv_0_filters: 256\n",
      "num_FullyConnected_layers: 1\n",
      "units_0: 64\n",
      "dropout: False\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "conv_1_filters: 64\n",
      "units_1: 256\n",
      "Score: 0.6964443325996399\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 32\n",
      "conv_1_kernel: 5\n",
      "pool_1_size: 5\n",
      "num_Convolutional_layers: 1\n",
      "conv_0_filters: 256\n",
      "num_FullyConnected_layers: 1\n",
      "units_0: 64\n",
      "dropout: True\n",
      "optimizer: adamax\n",
      "learning_rate: 0.001\n",
      "conv_1_filters: 64\n",
      "units_1: 64\n",
      "Score: 0.6994158625602722\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./keras_tuner/best_hyperparameter_tuned_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./keras_tuner/best_hyperparameter_tuned_model\\assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save(\"./keras_tuner/\" + 'best_hyperparameter_tuned_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77d2863d73a71357c1b21020a724e0f97bba5dba955c696759ed2a19762b4d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
