{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from keras import layers, regularizers, optimizers, losses\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocessing\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.utils import set_random_seed, image_dataset_from_directory\n",
    "from training import prepare_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "DATASET_PATH = \"../../../dataset/\"\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = (224, 224, 3, )\n",
    "\n",
    "# `PYTHONHASHSEED` environment variable\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "# Python built-in random, numpy(+ scikit) and tensorflow seed\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset...\n",
      "Found 11220 files belonging to 2 classes.\n",
      "Train dataset loaded!\n",
      "Labels in the dataset:  ['savory', 'unsavory']\n",
      "Loading validation dataset...\n",
      "Found 600 files belonging to 2 classes.\n",
      "Validation dataset loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "print(\"Loading train dataset...\")\n",
    "train_ds = image_dataset_from_directory(\n",
    "    directory=os.path.join(DATASET_PATH, \"train\"),\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=None,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=None,\n",
    "    seed=SEED\n",
    "    )\n",
    "print(\"Train dataset loaded!\")\n",
    "print(\"Labels in the dataset: \", train_ds.class_names)\n",
    "\n",
    "# Load the validation dataset\n",
    "print(\"Loading validation dataset...\")\n",
    "val_ds = image_dataset_from_directory(\n",
    "    directory=os.path.join(DATASET_PATH, \"valid\"),\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=None,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=None,\n",
    "    seed=SEED\n",
    "    )\n",
    "print(\"Validation dataset loaded!\")\n",
    "\n",
    "train_ds = train_ds.take(int(len(train_ds)*0.25))\n",
    "val_ds = val_ds.take(int(len(val_ds)*0.25))\n",
    "\n",
    "train_ds = prepare_dataset(train_ds, augment=True)\n",
    "val_ds = prepare_dataset(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.Input(shape=(INPUT_SHAPE)))\n",
    "    \n",
    "    # Search first conv\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv_1_filter', 32, 64),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(1e-2),\n",
    "        strides=(1, 1)\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D(pool_size=hp.Choice('pool_1_size', values = [3,5])))\n",
    "    \n",
    "    # Choose how many conv layers\n",
    "    for i in range(hp.Int(\"num_Convolutional_layers\", 1, 2)):\n",
    "        model.add(\n",
    "            layers.Conv2D(\n",
    "                filters=hp.Int(f\"conv_{i}_filters\", 64, 128, 256),\n",
    "                kernel_size=(3, 3),\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=regularizers.l2(1e-2),\n",
    "                strides=(1, 1)\n",
    "            )\n",
    "        )\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Choose how many classifier\n",
    "    for i in range(hp.Int(\"num_FullyConnected_layers\", 1, 2)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", 64, 128, 256),\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=regularizers.l2(1e-2)\n",
    "            )\n",
    "        )\n",
    "        if hp.Boolean(\"dropout\"): model.add(layers.Dropout(rate=0.25))\n",
    "    \n",
    "    model.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    # Choose the optimizer\n",
    "    hp_optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'adamax'], default = 'adamax')\n",
    "    optimizer = tf.keras.optimizers.get(hp_optimizer)\n",
    "    # Choose the learning rate\n",
    "    optimizer.learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-2], default = 1e-3)\n",
    "                                        \n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss=\"categorical_crossentropy\", \n",
    "                    metrics = [\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./keras_tuner/\", exist_ok=True)\n",
    "tuner = kt.BayesianOptimization(build_model,\n",
    "                                objective=kt.Objective('val_loss', direction=\"min\"),\n",
    "                                directory='./keras_tuner',\n",
    "                                max_trials = 20, overwrite=False,\n",
    "                                project_name='tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 10\n",
      "conv_1_filter (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 64, 'step': 1, 'sampling': None}\n",
      "conv_1_kernel (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [3, 5], 'ordered': True}\n",
      "pool_1_size (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [3, 5], 'ordered': True}\n",
      "num_Convolutional_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 2, 'step': 1, 'sampling': None}\n",
      "conv_0_filters (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 128, 'step': 256, 'sampling': None}\n",
      "num_FullyConnected_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 2, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 128, 'step': 256, 'sampling': None}\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "optimizer (Choice)\n",
      "{'default': 'adamax', 'conditions': [], 'values': ['adam', 'rmsprop', 'adamax'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.01], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "# The combination of all parameters\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 00m 29s]\n",
      "val_loss: 0.7256388068199158\n",
      "\n",
      "Best val_loss So Far: 0.7145437598228455\n",
      "Total elapsed time: 00h 14m 40s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=12, min_delta=0.0001, restore_best_weights=True, verbose=1)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.001, patience=5, verbose=1)\n",
    "callbacks = [early_stopping, lr_scheduler]\n",
    "# Search best hyperparameter\n",
    "tuner.search(train_ds, epochs=150, validation_data=val_ds, shuffle=True, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 256)       295168    \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 423,042\n",
      "Trainable params: 422,530\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the top model\n",
    "models = tuner.get_best_models(num_models=1)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# best_model.build(input_shape=INPUT_SHAPE)\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./keras_tuner\\tuned_model\n",
      "Showing 10 best trials\n",
      "Objective(name='val_loss', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_classifier: 2\n",
      "activation: relu\n",
      "dense_size_0: 64\n",
      "dropout_dense_0: 0.4\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "dense_size_1: 256\n",
      "dropout_dense_1: 0.4\n",
      "Score: 0.7145437598228455\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_classifier: 2\n",
      "activation: relu\n",
      "dense_size_0: 64\n",
      "dropout_dense_0: 0.4\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "dense_size_1: 256\n",
      "dropout_dense_1: 0.4\n",
      "Score: 0.7179487347602844\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_classifier: 2\n",
      "activation: relu\n",
      "dense_size_0: 256\n",
      "dropout_dense_0: 0.4\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "dense_size_1: 256\n",
      "dropout_dense_1: 0.4\n",
      "Score: 0.7217609882354736\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_classifier: 1\n",
      "activation: relu\n",
      "dense_size_0: 128\n",
      "dropout_dense_0: 0.4\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "Score: 0.7218497395515442\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_classifier: 2\n",
      "activation: relu\n",
      "dense_size_0: 256\n",
      "dropout_dense_0: 0.4\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "dense_size_1: 256\n",
      "dropout_dense_1: 0.0\n",
      "Score: 0.7229769229888916\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_classifier: 2\n",
      "activation: relu\n",
      "dense_size_0: 256\n",
      "dropout_dense_0: 0.4\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "dense_size_1: 64\n",
      "dropout_dense_1: 0.0\n",
      "Score: 0.7234817147254944\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_classifier: 1\n",
      "activation: relu\n",
      "dense_size_0: 64\n",
      "dropout_dense_0: 0.4\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "dense_size_1: 256\n",
      "dropout_dense_1: 0.4\n",
      "Score: 0.723488986492157\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_classifier: 1\n",
      "activation: relu\n",
      "dense_size_0: 64\n",
      "dropout_dense_0: 0.4\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "dense_size_1: 256\n",
      "dropout_dense_1: 0.4\n",
      "Score: 0.7241738438606262\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_classifier: 2\n",
      "activation: relu\n",
      "dense_size_0: 64\n",
      "dropout_dense_0: 0.4\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "dense_size_1: 256\n",
      "dropout_dense_1: 0.4\n",
      "Score: 0.7243878841400146\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_classifier: 1\n",
      "activation: relu\n",
      "dense_size_0: 64\n",
      "dropout_dense_0: 0.4\n",
      "optimizer: rmsprop\n",
      "learning_rate: 0.001\n",
      "dense_size_1: 256\n",
      "dropout_dense_1: 0.4\n",
      "Score: 0.7245272397994995\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./keras_tuner/best_hyperparameter_tuned_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./keras_tuner/best_hyperparameter_tuned_model\\assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save(\"./keras_tuner/\" + 'best_hyperparameter_tuned_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb528fd416c0ff975b48fb7dd275c91a0873308d73117ccfdcc096d65948d1b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
